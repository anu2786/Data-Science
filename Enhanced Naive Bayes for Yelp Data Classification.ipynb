{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c3246c1-e54d-4454-bc1c-901aa76419a0",
   "metadata": {},
   "source": [
    "# REPORT\r\n",
    "\r\n",
    "## Motivation: \r\n",
    "We were given yelp dataset which contained various attributes for each point of interest. The attributes given were name, latitude, longitude, mean check in time and reviews. Different categories were nightlife, restaurant and shopping. We need to create a Naive Bayes Classifier which correctly predicts the category of points of interest from the yelp dataset. We will use the review text and later name text to capture important patterns that can differentiate between different categories. The models created are simple, efficient and easy to use. Multinomial Naive Bayes can be considered a good classifier if we want to work on text features. It handles word count efficiently and assumes feature independence.\r\n",
    "\r\n",
    "## Data Representation and Preprocessing:\r\n",
    "In Task1 we have used 'review' text to represent the data.  \r\n",
    "In Task 2 we have used 'name' as an additional feature to represent data.  \r\n",
    "\r\n",
    "In both tasks for preprocessing data, we have used CountVectorizer from sklearn for text feature extraction. By using CountVectorizer we have done tokenization (a piece of text is broken down into words or tokens), Counting word frequency, vocabulary building and vectorization (convert each text piece into a vector representation based on the word counts). By converting both the review text and establishment names into numerical representations, we enable machine learning algorithms to process and analyse the data effectively.\r\n",
    "\r\n",
    "## Task 1:\r\n",
    "In task 1 we have only used 'review' feature to predict the category of Point of interest. Review contains rich information regarding each category. This text contains a lot of important information like menu items, prices, ambience of the place, which can help in training the model that can correctly classify the point of interest.  The review text was first transformed into numeric representation using CountVectorizer. The transformed data can easily be used to train Multinomial Naive Bayes Classifier. This creates a simple model.\r\n",
    "\r\n",
    "## Task 2:\r\n",
    "In task 2 we have used additional feature 'name' to represent the data and train our model on both 'name' and 'review' feature. The name of an establishment can provide a lot of keywords that can indicate its category. Example: 'Cafe', 'bar', 'boutique' can be considered as hints. Using both name and review features can improve the predictive power and accuracy of Naive Bayes Model by capturing a broader range of information. Other features such as GPS location and mean check in time do not provide much differentiation between the categories. We have combined these two features into one and then preprocessed the combined feature using CountVectorizer. This has helped in creating a simple and easy to implement model.\r\n",
    "\r\n",
    "## Evaluation Procedure:\r\n",
    "To evaluate the performance of the models we have used cross validation as well as test set accuracy. First we split our data into Training(80%) and Test(20%) set. By cross validation we have split the training data into 5 train-test folds. We computed performance metrics at each fold and then took a mean of all cross validation scores for each model. Then we tested our models on test data to measure accuracy of each model.\r\n",
    "\r\n",
    "## Training Results:\r\n",
    "\r\n",
    "### Task 1 result: \r\n",
    "Mean Cross Validation Score: 0.8488986784140969, Model Test Accuracy: 0.8855633802816901\r\n",
    "\r\n",
    "### Task 2 result: \r\n",
    "Mean Cross Validation Score: 0.866079295154185, Model Test Accuracy: 0.9014084507042254\r\n",
    "\r\n",
    "## Conclusion:\r\n",
    "So through cross validation score as well as test accuracy we can say that by using both name feature and review feature we are able to get a better model with better predictions. The second model is able to capture the underlying patterns more efficiently than the first model that used review only feature for category prediction. Model created in task 2 was used to predict the categories of point of interest for the test data that was given on Kaggle. The score came out to be 0.904               \r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc2422e-9fb2-45b4-8438-2b31b435efe1",
   "metadata": {},
   "source": [
    "## TASK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "525b42d2-55ba-4efd-a226-10adeca3628a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores: [0.82819383 0.85242291 0.85462555 0.86123348 0.84801762]\n",
      "Mean Cross Validation Score: 0.8488986784140969\n",
      "Model Test Accuracy: 0.8855633802816901\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "poi = pd.read_csv(\"train.csv\") #loading the data\n",
    "x = poi['review'] #Feature used is review only\n",
    "y = poi['category'] #Label\n",
    "\n",
    "#Splitting data into 20% testset\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Creating word matrix of 'review' using CountVectorizer (Preprocessing step)\n",
    "matrix = CountVectorizer()\n",
    "x_train_matrix = matrix.fit_transform(X_train)\n",
    "x_test_matrix = matrix.transform(X_test)\n",
    "\n",
    "#Training Naive Bayes Classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(x_train_matrix, y_train)\n",
    "\n",
    "#Cross Validation\n",
    "cv = cross_val_score(classifier, x_train_matrix, y_train, cv=5)\n",
    "mean_cv = np.mean(cv)\n",
    "print(\"Cross Validation Scores:\" , cv)\n",
    "print(\"Mean Cross Validation Score:\", mean_cv)\n",
    "\n",
    "#Evaluating model on test set\n",
    "y_pred = classifier.predict(x_test_matrix)\n",
    "Model_test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Model Test Accuracy:\", Model_test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3ec697-e684-4368-9250-2f8a63af8c1e",
   "metadata": {},
   "source": [
    "## TASK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b039ddb6-5c06-4fdd-ab82-3192b4cabfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores: [0.84140969 0.87885463 0.8722467  0.87444934 0.86343612]\n",
      "Mean Cross Validation Score: 0.866079295154185\n",
      "Model Test Accuracy: 0.9014084507042254\n"
     ]
    }
   ],
   "source": [
    "x_review = poi['review'] #Feature used is review only\n",
    "x_name = poi['name'] # One more feature added\n",
    "y = poi['category'] #Label\n",
    "\n",
    "#Combining 'review' and 'name' columns\n",
    "x_combined = x_review + ' ' + x_name\n",
    "\n",
    "#Splitting data into 20% testset\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_combined,y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "#Creating word matrix of 'review' and 'name' in a combined form using CountVectorizer (Preprocessing step)\n",
    "matrix = CountVectorizer()\n",
    "x_train_matrix = matrix.fit_transform(X_train)\n",
    "x_test_matrix = matrix.transform(X_test)\n",
    "\n",
    "#Training Naive Bayes Classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(x_train_matrix, y_train)\n",
    "\n",
    "#Cross Validation\n",
    "cv = cross_val_score(classifier, x_train_matrix, y_train, cv=5)\n",
    "mean_cv = np.mean(cv)\n",
    "print(\"Cross Validation Scores:\" , cv)\n",
    "print(\"Mean Cross Validation Score:\", mean_cv)\n",
    "\n",
    "#Evaluating model on test set\n",
    "y_pred = classifier.predict(x_test_matrix)\n",
    "Model_test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Model Test Accuracy:\", Model_test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
